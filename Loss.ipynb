{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdWkruqT8aFPUvFSbRUHIl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Training and Validation Loss"],"metadata":{"id":"jM3fQESYj3MZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AU69W9LNjqhN"},"outputs":[],"source":["# Training function with validation loss tracking\n","def train_pinn(model, X_train, Y_train, X_val, Y_val, epochs=20000, learning_rate=1e-5):\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    train_loss_history = []\n","    val_loss_history = []\n","\n","    for epoch in range(epochs):\n","        with tf.GradientTape() as tape:\n","            predictions = model(X_train)\n","            train_loss = tf.reduce_mean(tf.square(predictions - Y_train))\n","\n","        gradients = tape.gradient(train_loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","        # Compute validation loss\n","        val_predictions = model(X_val)\n","        val_loss = tf.reduce_mean(tf.square(val_predictions - Y_val))\n","\n","        train_loss_history.append(train_loss.numpy())\n","        val_loss_history.append(val_loss.numpy())\n","\n","        if epoch % 100 == 0:\n","            print(f\"Epoch {epoch}, Train Loss: {train_loss.numpy()}, Val Loss: {val_loss.numpy()}\")\n","\n","    return train_loss_history, val_loss_history\n","\n","# Parameters and initial conditions\n","params = (0.03, 0.01, 0.03, 0.03, 0.01, 0.095, 0.90, 0.03)\n","initial_conditions = [100, 5, 1, 0.0]\n","t = np.linspace(0, 50, 500)\n","\n","# Generate and normalize data\n","synthetic_data = generate_data(params, initial_conditions, t)\n","synthetic_data, y_min, y_max = normalize(synthetic_data)\n","t, t_min, t_max = normalize(t.reshape(-1, 1))\n","\n","# Split into training (80%) and validation (20%)\n","split_idx = int(0.8 * len(t))\n","X_train, X_val = t[:split_idx], t[split_idx:]\n","Y_train, Y_val = synthetic_data[:split_idx], synthetic_data[split_idx:]\n","\n","# Convert to tensors\n","X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n","Y_train = tf.convert_to_tensor(Y_train, dtype=tf.float32)\n","X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n","Y_val = tf.convert_to_tensor(Y_val, dtype=tf.float32)\n","\n","# Initialize and train the PINN\n","model = PINN()\n","train_loss_history, val_loss_history = train_pinn(model, X_train, Y_train, X_val, Y_val, epochs=20000, learning_rate=1e-5)\n","\n","# Plot training & validation loss\n","plt.figure(figsize=(8, 5))\n","plt.plot(train_loss_history, label=\"Training Loss\", color=\"b\")\n","plt.plot(val_loss_history, label=\"Validation Loss\", color=\"r\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training & Validation Loss\")\n","plt.legend()\n","plt.grid(True)"]}]}